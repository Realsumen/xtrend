{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "from models import *\n",
    "from dataprocessor import *\n",
    "def reload_custom_libs():\n",
    "    import models\n",
    "    import dataprocessor\n",
    "    importlib.reload(models)\n",
    "    importlib.reload(dataprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件中。。: 100%|██████████| 12/12 [00:59<00:00,  4.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot 编码中...\n",
      "one-hot 编码中...\n"
     ]
    }
   ],
   "source": [
    "macd_timescales = [(8, 24), (16, 28), (32, 96)]\n",
    "rtn_timescales = [1, 21, 63, 126, 252]\n",
    "timesteps = 126\n",
    "\n",
    "folder_path = 'data'\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "files = [file for file in files if file not in (\"CC00.NYB.xlsx\", \"LB00.CME.xlsx\", \"ES00.CME.xlsx\", \"NQ00.CME.xlsx\", \"YM00.CBT.xlsx\")]\n",
    "data_list = []\n",
    "\n",
    "\n",
    "data_list = process_data_list(files, macd_timescales, rtn_timescales, test = False)\n",
    "target_set, labels, map = generate_tensors(data_list, timesteps, encoder_type = \"one-hot\", return_map=True)\n",
    "context_set, _ = generate_tensors(data_list, timesteps, encoder_type = \"one-hot\", contain_next_day_rtn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理日期中..: 100%|██████████| 90358/90358 [39:33<00:00, 38.07it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = len(data_list)\n",
    "data_set = data_binder(context_set, target_set, labels, batch_size=batch_size)\n",
    "data_set.save(f\"saved_data\")\n",
    "\n",
    "dataset = tf.data.Dataset.load(\"saved_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_custom_libs()\n",
    "from models import *\n",
    "from dataprocessor import *\n",
    "\n",
    "hidden_dim = 64 # 128\n",
    "warm_up = 63\n",
    "target_std = tf.cast(5e-2, tf.float64)\n",
    "features_len = len(macd_timescales) + len(rtn_timescales)\n",
    "encoding_size = len(data_list) + 1\n",
    "x_shape = (batch_size, timesteps, features_len)\n",
    "s_shape = (batch_size, timesteps, encoding_size)\n",
    "\n",
    "model = ModelWrapper(features_len, hidden_dim, encoding_size, num_heads = 4)\n",
    "model.build((x_shape, s_shape))\n",
    "\n",
    "for data in dataset.take(1):\n",
    "    x_c, x_c_rtn, s_c, x, s, rtn_std, _, _ = data\n",
    "    result = model(x_c, x_c_rtn, s_c, x, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.12584984 -0.15766597 -0.31135345 ... -0.74588162 -0.69257611\n",
      "  -0.6935032 ]\n",
      " [ 1.8968035   1.89382064  2.03731036 ...  2.01342392  2.02806735\n",
      "   2.01587176]\n",
      " [ 1.81113768  1.93689287  2.02341795 ...  2.47515368  2.46943474\n",
      "   2.53876543]\n",
      " ...\n",
      " [ 1.96044993  1.84132099  1.78567052 ...  1.20581222  1.23146439\n",
      "   1.20552826]\n",
      " [ 0.09267747  0.06958246  0.08335954 ...  0.1735779   0.17149854\n",
      "   0.2484284 ]\n",
      " [-0.41665697 -0.43353912 -0.43934435 ... -0.44027138 -0.42002133\n",
      "  -0.36266631]], shape=(12, 126), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=7279.862473172699>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sharpe_loss(positions: tf.Tensor, rtn_std: tf.Tensor, target_std: float, warm_up: int):\n",
    "    rtn_std = tf.transpose(rtn_std, perm = [0, 2, 1])\n",
    "    target_std = tf.cast(target_std, tf.float64)\n",
    "    practice_timesteps = positions.shape[1] - warm_up\n",
    "    assets_daily_rtn = rtn_std[:, :, 0] / rtn_std[:, :, 1] * target_std * positions\n",
    "    portfolio_daily_rtn = tf.reduce_sum(assets_daily_rtn, axis=0)\n",
    "    portfolio_daily_rtn = portfolio_daily_rtn[-practice_timesteps:]\n",
    "    mean = tf.math.reduce_mean(portfolio_daily_rtn)\n",
    "    std = tf.math.reduce_variance(portfolio_daily_rtn) ** 0.5\n",
    "    loss = - 252 ** 0.5 * mean / std\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mle_loss(properties: tf.Tensor, rtn_std: tf.Tensor, target_std: float, warm_up: int):\n",
    "    batch_size = properties.shape[0]\n",
    "    time_steps = properties.shape[1]\n",
    "    rtn_std = tf.transpose(rtn_std, perm = [0, 2, 1])\n",
    "    mean, std = tf.squeeze(properties[:, :, 0])[-time_steps:], tf.squeeze(properties[:, :, 1])[-time_steps:]\n",
    "    assets_daily_change_pct = rtn_std[:, :, 0] / rtn_std[:, :, 1] * target_std\n",
    "    assets_daily_change_pct = assets_daily_change_pct[-time_steps:]\n",
    "    print(mean)\n",
    "    log_likelihood = -0.5 * tf.reduce_sum(\n",
    "        tf.math.log(2.0 * tf.constant(np.pi, tf.float64) * std**2) + ((assets_daily_change_pct - mean)**2 / (std**2))\n",
    "    )\n",
    "    loss = log_likelihood * -1 / batch_size / (time_steps - warm_up)\n",
    "    return loss \n",
    "    \n",
    "    \n",
    "\n",
    "# sharpe_loss(result[1], rtn_std, target_std, warm_up)\n",
    "mle_loss(result[0], rtn_std, target_std, warm_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=3.141592653589793>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtrend-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
