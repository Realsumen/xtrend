{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, ELU, Add, Softmax, LayerNormalization, LayerNormalization, MultiHeadAttention\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件中。。: 100%|██████████| 12/12 [00:50<00:00,  4.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "import dataprocessor\n",
    "importlib.reload(models)\n",
    "importlib.reload(dataprocessor)\n",
    "from models import *\n",
    "from dataprocessor import *\n",
    "\n",
    "macd_timescales = [(8, 24), (16, 28), (32, 96)]\n",
    "rtn_timescales = [1, 21, 63, 126, 252]\n",
    "timesteps = 16\n",
    "\n",
    "folder_path = 'data'\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "files = [file for file in files if file not in (\"CC00.NYB.xlsx\", \"LB00.CME.xlsx\", \"ES00.CME.xlsx\", \"NQ00.CME.xlsx\", \"YM00.CBT.xlsx\")]\n",
    "data_list = []\n",
    "\n",
    "\n",
    "data_list = process_data_list(files, macd_timescales, rtn_timescales, test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import dataprocessor\n",
    "importlib.reload(models)\n",
    "importlib.reload(dataprocessor)\n",
    "from models import *\n",
    "from dataprocessor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_set, labels = generate_tensors(data_list, timesteps, return_labels=True)\n",
    "context_set = generate_tensors(data_list, timesteps, contain_next_day_rtn=True)\n",
    "mean_set, std_set = labels\n",
    "\n",
    "target_features, target_dates, target_info = target_set\n",
    "context_features, context_dates, side_info = context_set\n",
    "target_info, index_word_map = side_info_tensor_encoder(target_info)\n",
    "side_info, _ = side_info_tensor_encoder(side_info)\n",
    "target_set = (target_features, target_dates, target_info)\n",
    "context_set = (context_features, context_dates, side_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_int(date):\n",
    "    date_int = tf.strings.to_number(tf.strings.regex_replace(date, \"-\", \"\"), tf.int32)\n",
    "    return date_int\n",
    "\n",
    "\n",
    "def find_matching_context(target_date, target_info, context_dates, context_features, side_info):\n",
    "    mask_date = tf.math.greater(date_to_int(target_date), date_to_int(context_dates))\n",
    "    mask_info = tf.reduce_all(tf.math.equal(target_info, side_info), axis=1)\n",
    "    mask_info = tf.logical_not(mask_info)\n",
    "    mask = tf.logical_and(mask_date, mask_info)\n",
    "    valid_indices = tf.where(mask)\n",
    "    if tf.size(valid_indices) > 0:\n",
    "        random_index = tf.random.uniform(shape=[], minval=0, maxval=tf.size(valid_indices), dtype=tf.int32)\n",
    "        selected_index = valid_indices[random_index, 0]\n",
    "        return context_features[selected_index], context_dates[selected_index], side_info[selected_index]\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "matched_context_features = []\n",
    "matched_context_dates = []\n",
    "matched_side_info = []\n",
    "matched_target_features = []\n",
    "matched_target_dates = []\n",
    "matched_target_info = []\n",
    "target_distribution = []\n",
    "\n",
    "for i in tqdm(range(len(target_dates))):\n",
    "    target_date = target_dates[i]\n",
    "    target_inf = target_info[i]\n",
    "    target_feature = target_features[i]\n",
    "    mean, std = mean_set[i], std_set[i]\n",
    "    \n",
    "    context_feature, context_date, side_inf = find_matching_context(\n",
    "        target_date, target_inf, context_dates, context_features, side_info)\n",
    "    \n",
    "    if context_feature is not None:\n",
    "        matched_context_features.append(context_feature)\n",
    "        matched_context_dates.append(context_date)\n",
    "        matched_side_info.append(side_inf)\n",
    "        matched_target_features.append(target_feature)\n",
    "        matched_target_dates.append(target_date)\n",
    "        matched_target_info.append(target_inf)\n",
    "        target_distribution.append((mean, std))\n",
    "\n",
    "if matched_context_features:\n",
    "    matched_context_features = tf.stack(matched_context_features)\n",
    "    matched_context_dates = tf.stack(matched_context_dates)\n",
    "    matched_side_info = tf.stack(matched_side_info)\n",
    "    matched_target_features = tf.stack(matched_target_features)\n",
    "    matched_target_dates = tf.stack(matched_context_dates)\n",
    "    matched_target_info = tf.stack(matched_side_info)\n",
    "    target_distribution = tf.stack(target_distribution)\n",
    "    \n",
    "else:\n",
    "    matched_context_features = tf.constant([])\n",
    "    matched_context_dates = tf.constant([])\n",
    "    matched_side_info = tf.constant([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_info(matched_side_info, time_steps):\n",
    "    expanded_info = tf.expand_dims(matched_side_info, axis=1)  # Shape will be [batch, 1, feature]\n",
    "    tiled_info = tf.tile(expanded_info, [1, time_steps, 1])\n",
    "    return tiled_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import dataprocessor\n",
    "importlib.reload(models)\n",
    "importlib.reload(dataprocessor)\n",
    "from models import *\n",
    "from dataprocessor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import dataprocessor\n",
    "importlib.reload(models)\n",
    "importlib.reload(dataprocessor)\n",
    "from models import *\n",
    "from dataprocessor import *\n",
    "\n",
    "sequence_length = 8\n",
    "hidden_dim = 128\n",
    "encoding_size = 13\n",
    "\n",
    "model = ModelWrapper(sequence_length, hidden_dim, encoding_size, 4)\n",
    "model.build((matched_target_features.shape, expand_info(matched_target_info, 16).shape))\n",
    "model(matched_context_features[:, :, 1:], matched_context_features, expand_info(matched_side_info, 16), matched_target_features, expand_info(matched_target_info, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtrend-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
