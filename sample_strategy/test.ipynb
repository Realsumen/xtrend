{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import importlib\n",
    "import os\n",
    "import loss_functions\n",
    "import dataprocessor\n",
    "import model\n",
    "import pickle\n",
    "import change_point_detection\n",
    "from tqdm import tqdm\n",
    "from heartrate import trace\n",
    "\n",
    "def reload_custom_libs():\n",
    "    importlib.reload(loss_functions)\n",
    "    importlib.reload(dataprocessor)\n",
    "    importlib.reload(change_point_detection)\n",
    "    importlib.reload(model)\n",
    "\n",
    "\n",
    "\n",
    "reload_custom_libs()\n",
    "from change_point_detection import *\n",
    "from loss_functions import *\n",
    "from model import *\n",
    "from dataprocessor import *\n",
    "\n",
    "macd_timescales = [(8, 24), (16, 28), (32, 96)]\n",
    "rtn_timescales = [1, 21, 63, 126, 252]\n",
    "timesteps = 126\n",
    "folder_path = \"data\"\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得高斯变点片段\n",
    "# test = [0, 200]\n",
    "gaussion_process_list = []\n",
    "# for i in tqdm(range(15)):\n",
    "#     lines = [test[0] + 200 * i, test[1] + 200 * i]\n",
    "#     # 处理数据\n",
    "#     data_list = process_data_list(files, macd_timescales, rtn_timescales, test=lines)\n",
    "#     print(f\"{lines[0]}_{lines[1]}数据处理完成\")\n",
    "#     # 获得断点分割片段数据\n",
    "#     try:\n",
    "#         gaussion_process_list = get_segment_list(data_list=data_list)\n",
    "#     except:\n",
    "#         continue\n",
    "#     with open(f'segments/{lines[0]}_{lines[1]}.pkl', 'wb') as f:\n",
    "#         pickle.dump(gaussion_process_list, f)\n",
    "#     # 读取数据\n",
    "#     with open(f'segments/{lines[0]}_{lines[1]}.pkl', 'rb') as f:\n",
    "#         file = pickle.load(f)\n",
    "#         gaussion_process_list.extend(file)\n",
    "\n",
    "\n",
    "data_list = process_data_list(files, macd_timescales, rtn_timescales, first_date=20220101, fill=False)\n",
    "\n",
    "pkl_files = [f for f in os.listdir(\"segments\") if f.endswith(\".pkl\")]\n",
    "for file in pkl_files:\n",
    "    with open(\"segments/\" + file, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "        gaussion_process_list.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>side_info</th>\n",
       "      <th>rtn_next_day</th>\n",
       "      <th>rtn</th>\n",
       "      <th>macd_8_24</th>\n",
       "      <th>macd_16_28</th>\n",
       "      <th>macd_32_96</th>\n",
       "      <th>sigma</th>\n",
       "      <th>rtn_1</th>\n",
       "      <th>rtn_21</th>\n",
       "      <th>rtn_63</th>\n",
       "      <th>rtn_126</th>\n",
       "      <th>rtn_252</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, close, side_info, rtn_next_day, rtn, macd_8_24, macd_16_28, macd_32_96, sigma, rtn_1, rtn_21, rtn_63, rtn_126, rtn_252]\n",
       "Index: []"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_custom_libs()\n",
    "from change_point_detection import *\n",
    "from loss_functions import *\n",
    "from model import ModelWrapper\n",
    "from dataprocessor import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成数据： target_set 和 context_set\n",
    "asset_num, context_num = 10, 20\n",
    "with open(f'map.pkl', 'rb') as f:\n",
    "    word_index = pickle.load(f)\n",
    "target_set, labels, word_index = generate_tensors(data_list, time_steps=timesteps, encoder_type = \"one-hot\", word_index = word_index, return_map=True)\n",
    "target_set, context_set, labels = gaussian_data_binder(\n",
    "    data_list,\n",
    "    target_set,\n",
    "    labels,\n",
    "    map=word_index,\n",
    "    asset_num=asset_num,\n",
    "    context_num=context_num,\n",
    "    gaussion_process_list=gaussion_process_list,\n",
    ")\n",
    "\n",
    "# 设置参数\n",
    "target_std = tf.cast(5e-2, tf.float64)\n",
    "hidden_dim = 64  # 128\n",
    "warm_up = 63\n",
    "features_len = len(macd_timescales) + len(rtn_timescales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare 数据, 初始化数据集\n",
    "x, s = target_set[0], target_set[-1]\n",
    "x_c_rtn, x_c, s_c = context_set[0], context_set[0][:, :, :, 1:], context_set[-1]\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_c, x_c_rtn, s_c, x, s, labels))\n",
    "\n",
    "timesteps = x.shape[-2]\n",
    "features_len = x.shape[-1]\n",
    "encoding_size = s.shape[-1]\n",
    "x_shape = (None, asset_num, timesteps, features_len)\n",
    "s_shape = (None, asset_num, timesteps, encoding_size)\n",
    "\n",
    "# 初始化模型\n",
    "xtrend_model = ModelWrapper(features_len, hidden_dim, encoding_size, num_heads=4, dropout_rate=0.4)\n",
    "xtrend_model.build((x_shape, s_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"final_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtrend-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
